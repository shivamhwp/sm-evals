{
  "name": "sm-evals",
  "module": "index.ts",
  "type": "module",
  "scripts": {
    "start:server": "cd py-metrics && uv run uvicorn py_metrics.main:app --host 0.0.0.0 --port 8000 --reload",
    "delete:memories": "bun run src/scripts/delete-memories.ts",
    "download:dataset": "cd py-metrics && uv run src/py_metrics/scripts/download_beir.py",
    "list:datasets": "cd py-metrics && uv run src/py_metrics/scripts/list_datasets.py",
    "load:dataset": "bun run src/scripts/load-beir.ts",
    "search": "bun run src/evaluation/search/search-file-eval.ts",
    "evaluate": "bun run src/evaluation/evaluate-from-file.ts",
    "install:py-deps": "cd py-metrics && uv pip install -r requirements.txt"
  },
  "devDependencies": {
    "@types/bun": "latest",
    "@types/react": "^19.1.3",
    "@types/react-dom": "^19.1.3"
  },
  "peerDependencies": {
    "typescript": "^5.0.0"
  },
  "dependencies": {
    "@ai-sdk/openai": "^1.3.21",
    "ai": "^4.3.13",
    "dotenv": "^16.5.0"
  }
}
